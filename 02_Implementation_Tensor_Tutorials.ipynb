{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu3103/PyTorch/blob/main/Implementation_Tensor_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U2MLouHnUHEZ"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm6iYkLVUHEc"
      },
      "source": [
        "\n",
        "[Learn the Basics](intro.html) ||\n",
        "[Quickstart](quickstart_tutorial.html) ||\n",
        "**Tensors** ||\n",
        "[Datasets & DataLoaders](data_tutorial.html) ||\n",
        "[Transforms](transforms_tutorial.html) ||\n",
        "[Build Model](buildmodel_tutorial.html) ||\n",
        "[Autograd](autogradqs_tutorial.html) ||\n",
        "[Optimization](optimization_tutorial.html) ||\n",
        "[Save & Load Model](saveloadrun_tutorial.html)\n",
        "\n",
        "# Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
        "In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to [NumPy’s](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and\n",
        "NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see `bridge-to-np-label`). Tensors\n",
        "are also optimized for automatic differentiation (we'll see more about that later in the [Autograd](autogradqs_tutorial.html)_\n",
        "section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u3DemI35UHEe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NLGrPg6UHEf"
      },
      "source": [
        "## Initializing a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ouK9qzyaUHEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b17d3c1-8fbc-44ee-aa6d-96695550a454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Tensor: {x_data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6D0VQiJUHEg"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2MdZW-S7UHEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce4bc04-aa80-4b0b-9fe7-72bc48631c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy array: [[1 2]\n",
            " [3 4]] Data type: int64\n",
            "Tensor: tensor([[1, 2],\n",
            "        [3, 4]]) Data type: torch.int64\n"
          ]
        }
      ],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"Numpy array: {np_array} Data type: {np_array.dtype}\")\n",
        "print(f\"Tensor: {x_np} Data type: {x_np.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg7W598_UHEh"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Bk0otb0UHEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9e948c-ec6a-4b13-ac77-07f3995cd2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.5050, 0.2867],\n",
            "        [0.6103, 0.8560]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDD_JH0QUHEh"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I7lNWYUdUHEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a07587d-cd57-4f25-9f0d-04999f39f2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8154, 0.9182, 0.9543],\n",
            "        [0.2007, 0.1806, 0.4542]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjjgXaOaUHEi"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOom92uUHEi"
      },
      "source": [
        "## Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hLHbjX0oUHEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf96ce0-e7eb-4f4b-c82f-66b48ead12d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([[0.8618, 0.9722, 0.3992, 0.3770],\n",
            "        [0.2819, 0.6687, 0.6944, 0.9465],\n",
            "        [0.7925, 0.3070, 0.5423, 0.5085]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Tensor: {tensor}\")\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6aOP3YHUHEi"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Experiment to see what a random tensor looks like in the image format"
      ],
      "metadata": {
        "id": "LJNmqzx8Xa-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "tensor_test = torch.rand(28,28,1)\n",
        "plt.imshow(tensor_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "51KcpD1bW7Vq",
        "outputId": "2dfbcff6-89a3-452c-e881-2da111886843"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f32a04ba470>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38jjl2ewUHEi"
      },
      "source": [
        "## Operations on Tensors\n",
        "\n",
        "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n",
        "indexing, slicing), sampling and more are\n",
        "comprehensively described [here](https://pytorch.org/docs/stable/torch.html)_.\n",
        "\n",
        "Each of these operations can be run on the GPU (at typically higher speeds than on a\n",
        "CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n",
        "``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n",
        "across devices can be expensive in terms of time and memory!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bFx40rcGUHEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fa60ec-f8b5-4789-9264-9d68a66db584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")\n",
        "print(f\"Device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoxPDyzeUHEj"
      },
      "source": [
        "Try out some of the operations from the list.\n",
        "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK6x0N-KUHEj"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2dl9QolkUHEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611a61f5-78a6-41cd-d707-90f1d39852be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJ0xKYuUHEj"
      },
      "source": [
        "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
        "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
        "another tensor joining operator that is subtly different from ``torch.cat``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "usFeBw96UHEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c035d20a-a768-4e19-a932-79a1b6ffc8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViR8jndVUHEj"
      },
      "source": [
        "**Arithmetic operations**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tkmqHKC6UHEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4c7b56-bc59-429b-a7c4-988f82b1e2d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-ocCrVUHEk"
      },
      "source": [
        "**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n",
        "values of a tensor into one value, you can convert it to a Python\n",
        "numerical value using ``item()``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EBFgNFRHUHEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49cb95b-9dc3-475f-b794-86e84a68f25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SliMXG1jUHEk"
      },
      "source": [
        "**In-place operations**\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n",
        "For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5GN2kYvzUHEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3caa087-5996-40ad-96b2-bf865fc68b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAIxrmIeUHEk"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4><b>Note</b></h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n",
        "     of history. Hence, <i><b>their use is discouraged.</i></b></p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlcweZw6UHEk"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiyO1NvlUHEk"
      },
      "source": [
        "\n",
        "## Bridge with NumPy\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
        "locations, and changing one will change\tthe other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTOuio4eUHEk"
      },
      "source": [
        "### Tensor to NumPy array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ByKz5tq_UHEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546a4be6-10ec-4986-f2b1-a52e21d8f1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yts_fYBUUHEk"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vCb3tDXRUHEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34f6261-e46f-4b0c-cceb-2db968c4ff18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf0qfM-sUHEl"
      },
      "source": [
        "### NumPy array to Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-jdGwcT4UHEl"
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2HVY0o7UHEl"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lDw5k_53UHEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed185c4-158a-4986-9532-c0744eb707cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xeuq9gbsZXVe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
